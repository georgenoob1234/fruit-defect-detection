# Fruit Defect Detection Configuration (Single YOLO Model)
model:
  primary_model_path: "models/fruit_defect_model.onnx"
  input_size: [320, 320]
  confidence_threshold: 0.7
  defect_confidence_threshold: 0.6
  iou_threshold: 0.5

fruits:
  classes: ["apple", "banana", "tomato"]
  defect_classes: ["defect"]  # Single agnostic defect class

detection:
  mode: "segmentation"  # or "detection" depending on your model
  defect_detection_enabled: true
  multi_label_detection: false  # Single model handles both fruit and defect

ui:
  hint_text: "Take another nearby"
  hint_duration: 2  # seconds
  display_confidence: true
  show_defect_overlay: true
  overlay_color: [0, 0, 255]  # Red for defects

performance:
  max_inference_time: 200  # milliseconds
  adaptive_resolution:
    enabled: true
    base_size: [320, 320]
    upscale_size: [384, 384]
    downscale_size: [256, 256]
    confidence_threshold_for_upscale: 0.4
    confidence_threshold_for_downscale: 0.8

ood_detection:
  enabled: true
  threshold: 0.5

logging:
  log_file: "logs/detection_events.csv"
  log_level: "INFO"
  log_defect_confidence: true
  log_fruit_confidence: true

camera:
  source: 0  # Default camera
  fps: 30
  resolution: [640, 480]

confidence:
  defect_detection:
    min_threshold: 0.5
    warning_threshold: 0.7
    high_confidence_threshold: 0.85